{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project3_GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMgF2KQLMOBuhgzutK8yymI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/channachot/Project1/blob/master/Project3_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3Sr7LA4mD6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqQ-TYGqmOcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_channels = 3\n",
        "latent_size = 100\n",
        "base_size, image_size, batch_size = 64, 64, 64\n",
        "torch.cuda.set_device(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwctTItNmPJi",
        "colab_type": "text"
      },
      "source": [
        "#Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fptYWby6mOfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    transforms.Resize(image_size),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # makes value in between [-1, 1]\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder('Project1/Animes', transform=transform)\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bijwe8EQmOhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_batch = next(iter(loader))\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0][:32], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-yCXL33mZDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Network\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "    \n",
        "class UnFlatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), 128, image_size//4, image_size//4)\n",
        "\n",
        "def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n",
        "                     nn.LeakyReLU(0.2, inplace=True),\n",
        "                     nn.Dropout2d(0.25)\n",
        "                    ]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsJtAK8WmZGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generator\n",
        "G = nn.Sequential(\n",
        "    nn.Linear(100, 128 * (image_size//4) ** 2),\n",
        "    UnFlatten(),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.Upsample(scale_factor=2),\n",
        "    nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "    nn.BatchNorm2d(128, 0.8),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.Upsample(scale_factor=2),\n",
        "    nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "    nn.BatchNorm2d(64, 0.8),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.Conv2d(64, num_channels, 3, stride=1, padding=1),\n",
        "    nn.Tanh(),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWO6q_sAmZJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Discriminator\n",
        "D = nn.Sequential(\n",
        "    *discriminator_block(num_channels, 16, bn=False),\n",
        "    *discriminator_block(16, 32),\n",
        "    *discriminator_block(32, 64),\n",
        "    *discriminator_block(64, 128),\n",
        "    Flatten(),\n",
        "    nn.Linear(128 * (image_size//2**4) ** 2, 1), \n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaoCm8YemZMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "\n",
        "# recursively apply weights initialization on every submodule\n",
        "G.apply(weights_init)\n",
        "D.apply(weights_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aDeTO73mZOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_my_picture():\n",
        "    Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_size))))\n",
        "    img = G(z).cpu().data[0]\n",
        "    img = img.view((num_channels, image_size, image_size)).transpose(0, 1).transpose(1, 2).cpu().numpy()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img.reshape(image_size, image_size, num_channels))\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAY9TgJ7mZSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    D.load_state_dict(torch.load('D.pth'))\n",
        "    G.load_state_dict(torch.load('G.pth'))\n",
        "except:\n",
        "    print(\"Weights not found ):\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6jg4oV6mZXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda = True if torch.cuda.is_available() else False\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "if cuda:\n",
        "    G.cuda()\n",
        "    D.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "    Tensor = torch.cuda.FloatTensor\n",
        "else:\n",
        "    Tensor = torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL7v6vxbmv7Q",
        "colab_type": "text"
      },
      "source": [
        "#Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc8yQaemmZWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 30\n",
        "learning_rate = 1e-3\n",
        "\n",
        "optim_G = torch.optim.Adam(G.parameters(), lr=learning_rate)\n",
        "optim_D = torch.optim.Adam(D.parameters(), lr=learning_rate)\n",
        "criterion_G = nn.BCELoss()\n",
        "criterion_D = nn.BCELoss()\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    for imgs, _ in loader:\n",
        "        # Train Generator\n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        optim_G.zero_grad()\n",
        "\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_size)))) # Sample noise\n",
        "        gen_imgs = G(z)\n",
        "        G_loss = adversarial_loss(D(gen_imgs), valid)\n",
        "\n",
        "        G_loss.backward()\n",
        "        optim_G.step()\n",
        "\n",
        "        #  Train Discriminator\n",
        "        optim_D.zero_grad()\n",
        "        real_loss = adversarial_loss(D(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(D(gen_imgs.detach()), fake)\n",
        "        D_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        D_loss.backward()\n",
        "        optim_D.step()\n",
        "    if epoch % 2 == 0:\n",
        "        D.eval()\n",
        "        G.eval()\n",
        "        draw_my_picture()        \n",
        "        print(f\"D_loss: {D_loss.item():.4f} G_loss: {G_loss.item():.4f}\")\n",
        "        torch.save(D.state_dict(), 'D.pth')\n",
        "        torch.save(G.state_dict(), 'G.pth')\n",
        "        D.train()\n",
        "        G.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dczWkCJ1mZRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = Variable(Tensor(np.random.normal(0, 1, (32, latent_size)))) # Sample noise\n",
        "gen_imgs = G(z).detach().cpu()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(gen_imgs, padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9qp54ARmOjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}